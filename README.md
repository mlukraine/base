Digital Police ML
===========

Данный репозиторий предназначен для работы с данными Digital Police. Основной
задачей является построение модели, которая позволит по исходным данным
предсказывать вероятность возникновение правонарушения в конкретной точке и
модели, которая по исходным параметрам позволит определить тип правонарушения.

### Структура проекта:

1. Data - дополнительные данные, которые могут быть использованы при решении.
Например, можно предположить, что данные о погодных условиях или скачке курса
валюты могут дополнительно влиять на возникновения ряда правонарушений.
2. Maps - тепловые карты, отражающие плотность правонарушений. Возможно
визуально оценить условную вероятность правонарушений в зависимости от времени,
дня недели и типов правонарушений.
3. Scripts - скрипты, использующиеся для решения задачи. Пока ориентировочно R
или Python.
4. Исходный массив данных или массив данных, подготовленный для обработки,
можно получить по запросу.

### Этапы работы:

- [x] Предварительное геокодирование адресов, по которым происходили
правонарушения.

> Для решения задачи были использованы данные Open Street Maps и Nominatim.
Данные по времени правонарушения были разбиты на дни недели и часы дня.


- [x] Генерация массива данных для обработки.

> В частности для каждого нарушения были определены расстояние до центра города,
привязаны данные по курсу валюты, погодные условия, указано наличие на
расстоянии 200 м тех или иных типов мест публичного пользования.

- [ ] Проведение эксплораторного анализа с целю определения наиболее эфеективных
для прогноза переменных.

- [ ] Для предсказания типов преступлений попробовать решения, предложенные в
Kaggle-соревновании ["San Francisco Crime Classification"](https://www.kaggle.com/c/sf-crime).

> Ожидаем наличие дополнительных вычислительных мощностей, можем использовать
базовые скрипты для R. Дополнительная подзадача - переписать существующие
решения для реализации параллельных вычислений.

- [ ] Для предсказания вероятности правонарушений предложено преобразование
исходных данных - от конкретных кейсов к условным вероятностям (см. ниже).

- [ ] Для преобразованной базы данных с условными вероятностями предложить
алгоритмы для прогнозирования новых вероятностей и предложить схему валидации.

---

### Создание массива с условными вероятностями

Проблема заключается в том, что наша база состоит исключительно из положительных
кейсов. А возможное количество негативных кейсов слишком велико.

Предлагается для каждой точки, где произошло правонарушение, расчитать условную
вероятность правонарушения в конкретное время и в конкретный день недели и для
конкретного типа правонарушения. А потом строить модель на подобным образом
аггрегированных данных. Здесь же возникает вопрос о том, что подобным образом
можно учесть дискретные данные. Для каждой точки получится
24\*7\*(типы правонарушения) строк данных. Но тогда неясно, как сюда учесть
непрерывные данные, например, разницу курсов, температуру и т.д.
Теоретически можно усреднить, но мне кажется, что я попросту теряю качество
данных (@Amice13).

Еще один вариант, который может быть интересен здесь: [http://stats.stackexchange.com/questions/174383/how-to-predict-outcome-with-only-positive-cases-as-training](http://stats.stackexchange.com/questions/174383/how-to-predict-outcome-with-only-positive-cases-as-training)

